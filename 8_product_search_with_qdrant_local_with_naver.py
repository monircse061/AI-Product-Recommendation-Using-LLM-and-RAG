import gradio as gr
from qdrant_client import QdrantClient
from qdrant_client.models import VectorParams, Distance, PointStruct
from openai import OpenAI
import random
import requests

# -------------------- Configuration --------------------
QDRANT_HOST = "localhost"
QDRANT_PORT = 6333
COLLECTION_NAME = "1M_products"
VECTOR_DIM = 1536
OPENAI_API_KEY = ""  # Replace with your key
NAVER_CLIENT_ID = ""
NAVER_CLIENT_SECRET = ""

# -------------------- Initialize Clients --------------------
qdrant_client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# -------------------- Embedding Function --------------------
def embed_text(text):
    response = openai_client.embeddings.create(input=text, model="text-embedding-ada-002")
    return response.data[0].embedding

# -------------------- Qdrant Search --------------------
def search_qdrant(query, top_k=5):
    query_vector = embed_text(query)
    hits = qdrant_client.search(
        collection_name=COLLECTION_NAME,
        query_vector=query_vector,
        limit=top_k
    )
    return [hit.payload for hit in hits]

# -------------------- Naver API Call --------------------
def fetch_naver_products(query, limit=2):
    url = "https://openapi.naver.com/v1/search/shop.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
    }
    params = {
        "query": query,
        "display": limit
    }
    response = requests.get(url, headers=headers, params=params)
    results = []

    if response.status_code == 200:
        items = response.json().get("items", [])
        for item in items:
            results.append({
                "ìƒí’ˆì½”ë“œ": item.get("productId", f"NAVER-{random.randint(10000,99999)}"),
                "ì›ë³¸ìƒí’ˆëª…": item.get("title", "").replace("<b>", "").replace("</b>", ""),
                "ê°€ê²©": int(item.get("lprice", 0)),
                "ë°°ì†¡ë¹„ìš©": 2500,
                "ì›ì‚°ì§€": "í•œêµ­",
                "ì´ë¯¸ì§€ëŒ€URL": item.get("image", "https://via.placeholder.com/150")
            })
    return results

# -------------------- LLM Reasoning --------------------
def generate_response_with_llm(query, product_infos, history=[]):
    context = "\n".join([f"- {p['ì›ë³¸ìƒí’ˆëª…']} ({p['ê°€ê²©']}ì›, {p['ì›ì‚°ì§€']})" for p in product_infos])
    prompt = (
        f"You are a helpful shopping assistant. A user asked: '{query}'.\n\n"
        f"Here are 5 products:\n{context}\n\n"
        "Give a friendly product recommendation summary."
    )
    messages = [{"role": "user", "content": prompt}]
    response = openai_client.chat.completions.create(model="gpt-3.5-turbo", messages=messages)
    return response.choices[0].message.content

# -------------------- Chatbot Logic --------------------
def chatbot_response(user_input, history):
    history = history[-5:] if history else []

    combined_query = " ".join([msg["content"] for msg in history if msg["role"] == "user"])
    combined_query += " " + user_input

    ownerclan_results = search_qdrant(combined_query, top_k=5)
    ownerclan_top3 = ownerclan_results[:3]
    naver_results = fetch_naver_products(user_input, limit=2)
    all_products = ownerclan_top3 + naver_results

    reasoning = generate_response_with_llm(user_input, all_products, history)

    product_details = ""
    for p in all_products:
        product_details += (
            f"**ğŸ†” ìƒí’ˆì½”ë“œ**: {p['ìƒí’ˆì½”ë“œ']}\n"
            f"**ğŸ“¦ ìƒí’ˆëª…**: {p['ì›ë³¸ìƒí’ˆëª…']}\n"
            f"**ğŸ’° ê°€ê²©**: {p['ê°€ê²©']}ì›\n"
            f"**ğŸšš ë°°ì†¡ë¹„ìš©**: {p['ë°°ì†¡ë¹„ìš©']}ì›\n"
            f"**ğŸŒ ì›ì‚°ì§€**: {p['ì›ì‚°ì§€']}\n"
        )
        image_url = p.get("ì´ë¯¸ì§€ëŒ€URL", "").strip()
        if image_url and image_url.startswith("http"):
            product_details += f"![image]({image_url})\n\n"
        else:
            product_details += "ğŸ–¼ï¸ *(No image available)*\n\n"
        product_details += "---\n"

    if "no" in user_input.lower():
        product_details += random.choice([
            "ğŸ” Do you prefer a specific brand or color?",
            "ğŸ¨ Would you like to explore a different style or category?",
            "ğŸ·ï¸ Are you looking for products in a different price range?"
        ])

    full_response = reasoning + "\n\n" + product_details

    return {"role": "assistant", "content": full_response}, history + [
        {"role": "user", "content": user_input},
        {"role": "assistant", "content": full_response}
    ]

# -------------------- Gradio UI --------------------
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("## ğŸ›ï¸ Smart Picks: Your AI-Powered Shopping Buddy ğŸ¤–")
    gr.Markdown(
        """
        ğŸ‰ **Welcome to the AI-Powered Product Recommendation Assistant!** ğŸ›ï¸ğŸ¤–ğŸ§   
        Ask anything like:  
        - ğŸ‘œ "ì—¬ë¦„ìš© ì—¬ì„± ë°±íŒ© ì¶”ì²œí•´ì¤˜"  
        - ğŸ’¼ "Affordable winter bags"  
        ğŸ‘‰ Youâ€™ll get **TOP 5 products** with details and ğŸ–¼ï¸ image previews!
        """
    )

    chatbot = gr.Chatbot(label="Smart Product Assistant", type="messages", height=520)
    state = gr.State([])

    with gr.Row():
        user_input = gr.Textbox(label="Ask about products", placeholder="e.g., ì—¬ì„± ì—¬ë¦„ ì›í”¼ìŠ¤ ì¶”ì²œí•´ì¤˜")
        submit_btn = gr.Button("ğŸ” Ask")

    clear_btn = gr.Button("ğŸ§¹ Clear Chat")

    def handle_input(user_input, history):
        response, new_history = chatbot_response(user_input, history)
        return "", new_history, new_history

    submit_btn.click(handle_input, [user_input, state], [user_input, chatbot, state])
    user_input.submit(handle_input, [user_input, state], [user_input, chatbot, state])
    clear_btn.click(lambda: [], None, chatbot)

demo.launch()
 # cd qdrant
 # cargo run --release